------------------------------------------------------------###demux_paired_end.py###-------------------------------------------------------
__author__ = 'gpratt'


"""

Converts randomer + barcoded fastq files into something that can be barcode collapsed and mapped

"""

from collections import Counter, defaultdict
from itertools import izip
import gzip
import os
from optparse import OptionParser


def hamming(word1, word2):
    """
    Gets hamming distance between two words, this is an odd implementation because
    we actually want Ns to appear similar to other barcodes as this makes the results more stringent, not less
    :param word1:
    :param word2:
    :return:
    """
    return sum(a != b and not (a == "N" or b == "N") for a, b in izip(word1, word2))


def read_has_barcode(barcodes, read, max_hamming_distance=0):
    """
    Checks if read has one of the barcodes listed in barcodes list and returns back that barcode

    :param barcodes: list of barcode sequence
    :param read: str, read to check if barcode exists in
    :param hamming: max hamming distance between given barcode and barcode in read
    :return: returns best barcode match in read, none if none found
    """

    #This takes care of the edge case of some barcodes having Ns on the end
    effective_barcodes = {barcode.split("N")[0]: barcode for barcode in barcodes}

    barcode_lengths = {len(barcode) for barcode in effective_barcodes}
    closest_barcode = None
    #assumes larger barcodes are less likely, and searches for them first
    #for each barcode length see if known barcodes appear
    for barcode_length in sorted(barcode_lengths, reverse=True):
        #Gets min hamming distance between barcode in read and barcode in list, behavior undefined if tie
        read_barcode = read[:barcode_length]
        cur_length_barcodes = [barcode for barcode in effective_barcodes if len(barcode) == barcode_length]
        hamming_distances = {barcode: hamming(barcode, read_barcode) for barcode in cur_length_barcodes}
        min_barcode = min(hamming_distances, key=hamming_distances.get)
        if hamming_distances[min_barcode] <= max_hamming_distance:
            closest_barcode = effective_barcodes[min_barcode]
            break
    return closest_barcode, read_barcode


def reformat_read(name_1, seq_1, plus_1, quality_1,
                  name_2, seq_2, plus_2, quality_2, barcodes,
                  RANDOMER_LENGTH=2, max_hamming_distance=0):
    """ reformats read to have correct barcode attached
        name - read name
        seq - read sequence
        plus - +
        quality - read quality sequence this is a poor mans datastructure, designed for speed
        barcodes, dictionary of barcodes to search for

        returns str - barcode barcode found, str - randomer identified, str - reformateed read
    """


    barcode, actual_barcode = read_has_barcode(barcodes.keys(), seq_1, max_hamming_distance)
    barcode_length = len(barcode) if barcode is not None else 0

    randomer = seq_2[:RANDOMER_LENGTH]

    name_1 = name_1[0] + randomer + ":" + name_1[1:]
    seq_1 = seq_1[barcode_length:]
    quality_1 = quality_1[barcode_length:]

    name_2 = name_2[0] + randomer + ":" + name_2[1:]
    seq_2 = seq_2[RANDOMER_LENGTH:]
    quality_2 = quality_2[RANDOMER_LENGTH:]

    #if none appear the barcode is unassigned
    if barcode is None:
        barcode = "unassigned"

    result_1 = name_1 + seq_1 + plus_1 + quality_1
    result_2 = name_2 + seq_2 + plus_2 + quality_2

    return barcode, actual_barcode, randomer, result_1, result_2

if __name__ == "__main__":
    usage = """ takes raw fastq files and demultiplex inline randomer + adapter sequences  """
    parser = OptionParser(usage)
    parser.add_option("--fastq_1", dest="fastq_1", help="fastq file to barcode seperate")
    parser.add_option("--fastq_2", dest="fastq_2", help="fastq file to barcode seperate")

    parser.add_option("-b", "--barcodes", dest="barcodes", help="file of barcode / barcode id (tab sepearted, one barcode / barcode id on each line")
    parser.add_option("--out_file_1", dest="out_file_1")
    parser.add_option("--out_file_2", dest="out_file_2")
    parser.add_option("--length", type=int, dest="length", help="Number of randomers on the front of the second read", default=3)
    parser.add_option("--max_hamming_distance", type=int, dest="max_hamming_distance", help="Max Hamming distance between read barcode and given barcodes to assign a read to a given barcode", default=1)

    parser.add_option("-m", "--metrics_file", dest="metrics_file")

    (options,args) = parser.parse_args()

    #if a gziped file then we reassign open to be the gzip open and continue using that for the rest of the
    #program
    my_open = gzip.open if os.path.splitext(options.fastq_1)[1] == ".gz" else open
    #creates different barcode files to assign reads to

    RANDOMER_LENGTH = options.length

    barcodes = {}
    randomer_counts = {}
    with open(options.barcodes) as barcodes_file:
        for line in barcodes_file:
            line = line.strip().split("\t")
            split_file_1 = options.out_file_1.split(".")
            split_file_1.insert(-2, line[1])

            split_file_2 = options.out_file_2.split(".")
            split_file_2.insert(-2, line[1])

            barcodes[line[0]] = [gzip.open(".".join(split_file_1), 'w'),
                                 gzip.open(".".join(split_file_2), 'w'),
                                 ]

            randomer_counts[line[0]] = defaultdict(Counter)

    split_file_1 = options.out_file_1.split(".")
    split_file_1.insert(-2, "unassigned")

    split_file_2 = options.out_file_2.split(".")
    split_file_2.insert(-2, "unassigned")

    barcodes['unassigned'] = [gzip.open(".".join(split_file_1), 'w'),
                              gzip.open(".".join(split_file_2), 'w'),
                              ]
    randomer_counts['unassigned'] = defaultdict(Counter)

    #reads through initial file parses everything out
    with my_open(options.fastq_1) as fastq_file_1, my_open(options.fastq_2) as fastq_file_2, open(options.metrics_file, 'w') as metrics_file:
        while True:
            try:
                name_1 = fastq_file_1.next()
                seq_1 = fastq_file_1.next()
                fastq_file_1.next() #got to consume the read
                plus = "+\n" #sometimes the descriptor is here, don't want it
                quality_1 = fastq_file_1.next()

                name_2 = fastq_file_2.next()
                seq_2 = fastq_file_2.next()
                fastq_file_2.next() #got to consume the read
                plus = "+\n" #sometimes the descriptor is here, don't want it
                quality_2 = fastq_file_2.next()
                if name_1.split()[0] != name_2.split()[0]:
                    print name_1, name_2
                    raise Exception("Read 1 is not same name as Read 2")

                barcode, actual_barcode, randomer, result_1, result_2 = reformat_read(name_1, seq_1, plus, quality_1,
                                                                      name_2, seq_2, plus, quality_2,
                                                                      barcodes, RANDOMER_LENGTH,
                                                                      max_hamming_distance=options.max_hamming_distance)
                randomer_counts[barcode][actual_barcode][randomer] += 1
                barcodes[barcode][0].write(result_1)
                barcodes[barcode][1].write(result_2)
            except StopIteration:
                break
        for barcode, actual_barcodes in randomer_counts.items():
            for actual_barcode, randomers in actual_barcodes.items():
                for randomer, count in randomers.items():
                    metrics_file.write("%s\t%s\t%s\t%s\n" % (barcode, actual_barcode, randomer, count))

    #cleans up at the end
    for lst in barcodes.values():
        for fn in lst:
            fn.close()

------------------------------------------------------------###Removing PCR duplicates###-----------------------------
__author__ = 'gpratt'
"""

barcode_collapse.py  read in a .bam file where the
first 9 nt of the read name
are the barcode and merge reads mapped to the same position that have the same barcode

"""

from collections import Counter
import itertools
from optparse import OptionParser
import sys
import pysam


def stranded_read_start(read):
    if read.is_reverse:
        return read.positions[-1]
    else:
        return read.pos


def output_metrics(metrics_file, total_count, removed_count):
    with open(metrics_file, 'w') as metrics:
        metrics.write("\t".join(["randomer", "total_count", "removed_count"]) + "\n")
        for barcode in total_count.keys():
            metrics.write("\t".join(map(str, [barcode, total_count[barcode], removed_count[barcode]])) + "\n")


def barcode_collapse(in_bam, out_bam):
    number_of_unmapped_mate_pairs = 0
    different_chroms = 0
    removed_count = Counter()
    total_count = Counter()
    result_dict = {}

    with pysam.Samfile(in_bam, 'r') as samfile1:
        with pysam.Samfile(in_bam, 'r') as samfile2:
            samfile_read1 = itertools.islice(samfile1, 0, None, 2)
            samfile_read2 = itertools.islice(samfile2, 1, None, 2)
            for read1, read2 in itertools.izip(samfile_read1, samfile_read2):
                if not read1.qname == read2.qname:
                    print read1.qname, read2.qname
                    raise Exception("Read Names don't match")
                if read1.is_unmapped and read1.is_unmapped:
                    #Both reads don't map, don't even both saving them.
                    continue
                if (not read1.is_unmapped and read2.is_unmapped) or (read1.is_unmapped and read2.is_unmapped):
                    number_of_unmapped_mate_pairs += 1
                    continue
                if read1.rname != read2.rname:
                    different_chroms += 1
                    continue

                #if the read order is swapped swap everything before running.
                if not read1.is_read1:
                    read1, read2 = read2, read1

                randomer = read1.qname.split(":")[0]

                start = stranded_read_start(read1)
                stop = stranded_read_start(read2)
                read1.is_read1
                strand = "-" if read1.is_reverse else "+"
                unique_location = (read1.rname, start, stop, strand, randomer)
                total_count[randomer] += 1
                if unique_location in result_dict:
                    removed_count[randomer] += 1
                    continue

                result_dict[(read1.rname, start, stop, strand, randomer)] = (read1, read2)

        with pysam.Samfile(out_bam, 'wb', template=samfile1) as out_bam:
            for key, (read1, read2) in result_dict.items():
                out_bam.write(read1)
                out_bam.write(read2)
    return total_count, removed_count

if __name__ == "__main__":
    description=""""Paired End randomer aware duplciate removal algorithm."""
    usage="""Assumes paired end reads are adjectent to each other in output file (ie only provide unsorted bams)
             Also assumes no multimappers in the bam file, if there are multimappers behavior is undefined"""
    parser = OptionParser(usage=usage, description=description)
    parser.add_option("-b", "--bam", dest="bam", help="bam file to barcode collapse")
    parser.add_option("-o", "--out_file", dest="out_file")
    parser.add_option("-m", "--metrics_file", dest="metrics_file")
    (options, args) = parser.parse_args()

    if not (options.bam.endswith(".bam")):
        raise TypeError("%s, not bam file" % options.bam)

    total_count, removed_count = barcode_collapse(options.bam, options.out_file)
    output_metrics(options.metrics_file, total_count, removed_count)

    sys.exit(0)

-------------------------------------------###peakcalling ###-------------------------------------------------
#!/usr/bin/perl -w

use strict;
use warnings;

use File::Basename;
use Getopt::Long;

use MyConfig;
use Bed;
use ScanStatistics;

use Data::Dumper;

my $prog = basename ($0);
my $cmdDir = dirname ($0);

my $verbose = 0;
my $big = 0;
my $minBlockSize = 2000000;
my $separateStrand = 0;

my $valleySeeking = 0;	#0 or 1
my $valleyDepth = 0.9;	#0.9 as default

#my $confFile = "";
my $dbkey = "";

my $geneBedFile = "";
my $useExpr = 0;
my $pvalueThreshold = 0.01;
my $multiTestCorrection = 0;

my $minPH = 2;
my $maxPH = -1;
my $skipOutofRangePeaks = 0; #by default, peaks with PH> maxPH will be labeled with p=nd, but kept. This option is provided to reproduce results from a previous version

#calculation of scan statistics can be slow for very large peak height, and these might be spurious (e.g., in very abundant RNA) and one might filter them out
#5000; -1= no filter by default

my $maxGap = -1; #no merge by default, default 25 recommended if merge

my $outBoundaryBedFile = "";
my $outHalfPHBedFile = "";

my $prefix = "Peak";

my $cache = getDefaultCache ($prog);
my $keepCache = 0;

my @ARGV0 = @ARGV;

GetOptions (
	'big'=>\$big,
	'p:f'=>\$pvalueThreshold,
	'ss'=>\$separateStrand,
	'valley-seeking'=>\$valleySeeking,
	'valley-depth:f'=>\$valleyDepth,
	#'test'=>\$doStatTest,
	'dbkey:s'=>\$dbkey,
	'gene:s'=>\$geneBedFile,
	'use-expr'=>\$useExpr,
	'multi-test'=>\$multiTestCorrection,
	'minPH:i'=>\$minPH,
	'maxPH:i'=>\$maxPH,
	'skip-out-of-range-peaks'=>\$skipOutofRangePeaks,
	'gap:i'=>\$maxGap,
	'out-boundary:s'=>\$outBoundaryBedFile,
	'out-half-PH:s'=>\$outHalfPHBedFile,
	'prefix:s'=>\$prefix,
	'c|cache:s'=>\$cache,
	'keep-cache'=>\$keepCache,
	'v'=>\$verbose);


if (@ARGV != 2)
{
    print "detecting peaks from CLIP data\n";
    print "Usage: $prog [options] <tag.bed> <peak.bed>\n";
    print " <tag.bed> : BED file of unique CLIP tags, input\n"; #, use - for stdin\n";
	print " <peak.bed>: BED file of called peaks, output\n";
	print "Options:\n";
	#print " -e          : expression values indicated in the gene bed file\n";
    print " -big                   : big input file\n";
	print " -ss                    : separate the two strands\n";
	print " --valley-seeking       : find candidate peaks by valley seeking\n";
	print " --valley-depth [float] : depth of valley if valley seeking ($valleyDepth)\n";
	print " --out-boundary [string]: output cluster boundaries\n";
	print " --out-half-PH  [string]: output half peak height boundaries\n";
    print " --dbkey        [string]: species to retrieve the default gene bed file (mm10|hg19)\n";
	print " --gene         [string]: custom gene bed file for scan statistics (will override --dbkey)\n";
	print " --use-expr             : use expression levels given in the score column in the custom gene bed file for normalization\n";
	print " -p             [float] : threshold of p-value to call peak ($pvalueThreshold)\n";    
	print " --multi-test           : do Bonferroni multiple test correction\n";
	print " -minPH         [int]   : min peak height ($minPH)\n";
    print " -maxPH         [int]   : max peak height to calculate p-value($maxPH, no limit if < 0)\n";
	print " --skip-out-of-range-peaks: skip peaks with PH > maxPH\n";
	print " -gap           [int]   : merge cluster peaks closer than the gap ($maxGap, no merge if < 0)\n";
	print " --prefix       [string]: prefix of peak id ($prefix)\n";
    print " -c             [dir]   : cache dir\n";
	print " --keep-cache           : keep cache when the job done\n";
    print " -v                     : verbose\n";
    exit (0);
}

print "CMD=$prog ", join(" ", @ARGV0), "\n" if $verbose;

my ($tagBedFile, $outBedFile) = @ARGV;


#check parameters

if ($geneBedFile ne '' || $useExpr)
{
	Carp::croak "$geneBedFile does not exist\n" unless -f $geneBedFile;
}


#the lines below is expired because we check this later
#if ($dbkey ne '')
#{
#	Carp::croak "dbkey must be mm10 or hg19\n" unless $dbkey eq 'mm10' || $dbkey eq 'hg19';
#}


if ($valleySeeking)
{
	Carp::croak "valley-depth must be between 0.5 and 1\n" unless $valleyDepth >= 0.5 && $valleyDepth <= 1;
}
else
{
	#if no valley seeking, must specify genic region and do statistical test
	#also must do merging
	Carp::croak "must specify --dbkey or --gene when --valley-seeking is not unabled\n" unless $geneBedFile ne '' || $dbkey ne '';
	warn "peak merging is strongly recommended (e.g. --gap 25) without valley seeking\n" if $maxGap < 0;
}

if ($dbkey ne '')
{
	if ($geneBedFile eq '')
	{
		#get gene bed file
		my $confFile = "$cmdDir/ctk.loc";
		my $locationInfo = getLocationInfo ($confFile, $dbkey, "genic");
		Carp::croak "cannot locate genic bed file for $dbkey\n" unless exists $locationInfo->{'genic'};

		$geneBedFile = $locationInfo->{'genic'};
		print "gene bed file=$geneBedFile\n" if $verbose;

		Carp::croak "$geneBedFile does not exist\n" unless -f $geneBedFile;
	}
	#otherwise do nothing
}

if ($outBoundaryBedFile ne '' || $outHalfPHBedFile ne '')
{
	Carp::croak "must enable --valley-seeking\n" unless $valleySeeking;
}

if ($minPH < 2)
{
	warn "minPH must be >=2\n";
	$minPH = 2;
}


my $bigFlag = $big ? "-big" : "";
my $verboseFlag = $verbose ? "-v" : "";
my $ssFlag = $separateStrand ? "-ss" : "";

Carp::croak "$cache already exists\n" if -d $cache || -f $cache;
system ("mkdir $cache");


##
print "generate exact tag coverage profile ...\n" if $verbose;

my $tagExactCountBedFile = "$cache/tag.count.exact.bed";
my $tmpPeakBedFile = "$cache/tmp.peak.bed";

my $cmd = "perl $cmdDir/tag2profile.pl $verboseFlag $bigFlag -exact $ssFlag -of bed $tagBedFile $tagExactCountBedFile";
my $ret = system ($cmd);
Carp::croak "CMD=$cmd failed:$?\n" unless $ret == 0;


print "extract candidate peaks ...\n" if $verbose;

if ($valleySeeking)
{
	my %tagCount;
	my $cachePeak = "$cache/cache_peak";
	system ("mkdir $cachePeak");
	if ($big)
	{
		my $ret = splitBedFileByChrom ($tagExactCountBedFile, $cachePeak, v=>$verbose, "sort"=>1);
		%tagCount = %$ret;
	} 
	else
	{
		my $tags = readBedFile ($tagExactCountBedFile, $verbose);
	   	foreach my $t (@$tags)
    	{
        	my $chrom = $t->{"chrom"};
        	push @{$tagCount{$chrom}}, $t;
    	}
	}

	print "get positions with non-zero tag count broken down into chromosomes ...\n" if $verbose;

	foreach my $chrom (sort keys %tagCount)
	{

	    my $n = $tagCount{$chrom};
	    $n = ref($n) eq 'HASH' ? $n = $n->{'n'} : @$n;
	    print "$chrom : $n tags\n" if $verbose;
	}

	my @strand = ('b');
	@strand = qw(+ -) if $separateStrand;

	my $fout;
	open ($fout, ">$tmpPeakBedFile") || Carp::croak "cannot open file $tmpPeakBedFile to write\n";
	foreach my $s (@strand)
	{
		print "#processing strand $s ...\n" if $verbose;
		my @chroms = sort keys %tagCount;

		foreach my $chrom (@chroms)
		{
			print "processing chrom $chrom ...\n" if $verbose;
			if ($big)
			{
				my $tmpFile = $tagCount{$chrom}->{'f'};
				my $fin;
				open ($fin, "<$tmpFile") || Carp::croak "cannot open file $tmpFile to read\n";

				my $iter = 0;
				while (my $block = readNextBedBlock ($fin, 1, 0, minBlockSize=> $minBlockSize))
				{
					my $n = @$block;
					print "block $iter: $n positions\n" if $verbose;
					$iter++;
					my $peaks = extractPeaks ($block, $s, $valleyDepth);
					foreach my $p (@$peaks)
					{
						$p->{'name'} .= "#" . join ("#", $p->{'leftBoundary'}, $p->{'rightBoundary'}+1, $p->{'leftHalfPH'}, $p->{'rightHalfPH'}+1);
						print $fout bedToLine ($p), "\n" if $p->{'score'} >= $minPH;
					}
				}
				close ($fin);
			}
			else
			{
				my $tags = $tagCount{$chrom};
				my $n = @$tags;
				print "$n tags loaded on chromosome $chrom\n" if $verbose;
				my $peaks = extractPeaks ($tags, $s, $valleyDepth);

   	        	foreach my $p (@$peaks)
            	{
					$p->{'name'} .= "#" . join ("#", $p->{'leftBoundary'}, $p->{'rightBoundary'}+1, $p->{'leftHalfPH'}, $p->{'rightHalfPH'}+1);
            		print $fout bedToLine ($p), "\n" if $p->{'score'} >= $minPH;
            	}
			}
		}
	}
	close ($fout);
}
else
{
	my $cmd = "awk '{if (\$5>=$minPH) {print \$0}}' $tagExactCountBedFile > $tmpPeakBedFile";
	system ($cmd);
}


$cmd = "wc -l $tmpPeakBedFile | awk '{print \$1}'";
my $n = `$cmd`;
$n=~/^(\d+)/;
$n = $1;


if ($n == 0)
{
	Carp::croak "no peaks found\n";
	system ("rm -rf $cache") unless $keepCache;
	exit (0);
}

print "$n candidate peaks with PH>=$minPH detected\n" if $verbose;

#assign candidate peaks to genes and assess statistical significance

if (-f $geneBedFile)
{
	print "estimating average tag size ...\n" if $verbose;
	my $tagSize =  `awk 'BEGIN{s=0;n=0;} {s=s+\$3-\$2; n=n+1} END {print s/n}' $tagBedFile`;
	
	chomp $tagSize;
	print "average tag size = $tagSize\n" if $verbose;

	print "get exons in genes ... \n" if $verbose;
	my $ts2geneFile = "$cache/ts2gene.txt";
	my $cleanGeneBedFile = "$cache/gene.clean.bed";

	my $cmd = "awk '{print \$4\"\\t\"\$4}' $geneBedFile | sort | uniq > $ts2geneFile";
	system ($cmd);

	$cmd = "perl $cmdDir/combineTranscripts.pl $verboseFlag  $geneBedFile $ts2geneFile $cleanGeneBedFile";
	system ($cmd);

	my $exonBedFile = "$cache/exon.bed";
	$cmd = "perl $cmdDir/gene2ExonIntron.pl $verboseFlag -nid -oe $exonBedFile $cleanGeneBedFile";
	system ($cmd);


	print "count tag number for each exon/gene ...\n" if $verbose;
	my $exonTagCountBedFile = "$cache/tag.count.exon.bed";

	$cmd = "perl $cmdDir/tag2profile.pl $bigFlag $verboseFlag -region $exonBedFile $ssFlag -of bed $tagBedFile $exonTagCountBedFile";
	print $cmd, "\n";
	system ($cmd);

	my $fin;
	my $fout;

	my %geneTagCountHash;

	open ($fin, "<$exonTagCountBedFile") || Carp::croak "cannot open file $exonTagCountBedFile\n";
	while (my $line = <$fin>)
	{
	    chomp $line;
	    my $r = lineToBed ($line);

	    my $geneId = $r->{"name"};
	    $geneTagCountHash{$geneId}->{'size'} += ($r->{'chromEnd'} - $r->{'chromStart'} + 1);
	    $geneTagCountHash{$geneId}->{'count'} += $r->{'score'};
	}
	close ($fin);

	my $geneTagCountTotal = 0;
	map {$geneTagCountTotal += $geneTagCountHash{$_}->{'count'}} keys %geneTagCountHash;

	Carp::croak "no tags??" if $geneTagCountTotal <= 0;

	print "total number of tags overlapping with specified reions: $geneTagCountTotal\n" if $verbose;

	my $geneExpressionTotal = 0;
	if ($useExpr)
	{
		print "reading gene expression levels from $geneBedFile ...\n" if $verbose;
		open ($fin, "<$geneBedFile") || Carp::croak "cannot open file $geneBedFile to read\n";
		while (my $line = <$fin>)
		{
			chomp $line;
			next if $line =~/^\s*$/;
			next if $line =~/^track/;
			next if $line =~/^#/;

			my @cols = split (/\s+/, $line);
			Carp::croak "no score column in $geneBedFile ...\n" if @cols < 5;
		
			my $geneId = $cols[3];
			my $expr = $cols[4];
		
			Carp::croak "expression value for gene $geneId is negative\n" if $expr < 0;
			$geneTagCountHash{$geneId}->{'expr'} = $expr if exists $geneTagCountHash{$geneId};
		}
		close ($fin);

		map {$geneExpressionTotal += $geneTagCountHash{$_}->{'expr'}} keys %geneTagCountHash;
		Carp::croak "all genes have no expression??\n" if $geneExpressionTotal <= 0;

		print "total gene expression level: $geneExpressionTotal\n" if $verbose;
	}

	print "calculating expected peak height for each gene ...\n" if $verbose;


#my $geneTagCountFile = "$cache/tag.count.gene.txt";
#open ($fout, ">$geneTagCountFile") || Carp::croak "cannot open file $geneTagCountFile to write\n";

#if ($useExpr)
#{
#	print $fout "#", join ("\t", "gene id", "size", "tag number", "tag density", "expression", "expexpted PH"), "\n";
#}
#else
#{
#	print $fout "#", join ("\t", "gene id", "size", "tag number", "tag density", "expexpted PH"), "\n";
#}

	foreach my $geneId (sort keys %geneTagCountHash)
	{
		my $g = $geneTagCountHash{$geneId};
	    $g->{'density'} = $g->{'count'} / $g->{'size'};
		$g->{'PH0'} = $useExpr ? ($geneTagCountTotal * $g->{'expr'} / $geneExpressionTotal / $g->{'size'} * $tagSize) : ($g->{'density'} * $tagSize);

#	if ($useExpr)
#	{
#		print $fout join ("\t", $geneId, $g->{'size'}, $g->{'count'}, $g->{'density'}, $g->{'expr'}, $g->{'PH0'}), "\n";
#	}
#	else
#	{
#		print $fout join ("\t", $geneId, $g->{'size'}, $g->{'count'}, $g->{'density'}, $g->{'PH0'}), "\n";
#	}

	}
#close ($fout);

#my $effectiveGeneNum = `awk '{if(\$3>0) {print \$0}}' $geneTagCountFile | wc -l | awk '{print \$1}'`;
#$effectiveGeneNum =~/\s*(\d+)\s*/;
#$effectiveGeneNum = $1;

	my $effectiveGeneNum = 0;

	if ($useExpr)
	{
		map {$effectiveGeneNum++ if $geneTagCountHash{$_}->{'expr'} > 0} keys %geneTagCountHash;
	}
	else
	{
		map {$effectiveGeneNum++ if $geneTagCountHash{$_}->{'count'} > 0} keys %geneTagCountHash;
	}

	print "effective gene number: $effectiveGeneNum\n" if $verbose;


	#this part can be improved
	#e.g. 1. if two genes overlap with each other resulting in ambiguity, exonic region should have higher priority
	#     2. peaks in the extended 3' UTR region

	print "match peaks with genes ...\n" if $verbose;
	my $peak2geneBedFile = "$cache/peak2gene.bed";
	$cmd = "perl $cmdDir/tagoverlap.pl $bigFlag $verboseFlag -d \"@@\" --keep-score -region $cleanGeneBedFile $ssFlag $tmpPeakBedFile $peak2geneBedFile";
	system ($cmd);


	print "calculate pvalues ...\n" if $verbose;

	$tmpPeakBedFile = "$cache/tmp.peak.sig.bed";
	open ($fin, "<$peak2geneBedFile") || Carp::croak "cannot open file $peak2geneBedFile to read\n";
	open ($fout, ">$tmpPeakBedFile") || Carp::croak "cannot open file $tmpPeakBedFile to write\n";

	my %resultHash;
	my $i = 0;

	my $npeak = 0;
	while (my $line = <$fin>)
	{
	    chomp $line;

	    print "$i ...\n" if $verbose && $i % 5000 == 0;
	    $i++;

	    my $peak = lineToBed ($line);
	    my $name = $peak->{'name'};
	    my $peakHeight = $peak->{'score'};

	    my ($peakId, $geneId) = split ("@@", $name);
		my ($leftBoundary, $rightBoundary, $leftHalfPH, $rightHalfPH);

		($peakId, $leftBoundary, $rightBoundary, $leftHalfPH, $rightHalfPH) = split ("#", $peakId) if $valleySeeking;

    	next unless exists $geneTagCountHash{$geneId};

    	my $expectedPeakHeight = $geneTagCountHash{$geneId}->{'PH0'}; #expected PH
    	next unless $expectedPeakHeight > 0; #otherwise no tag on the exonic region of the gene
    	next unless $peakHeight > $expectedPeakHeight;#otherwise it cannot be significant

    	my $geneSize = $geneTagCountHash{$geneId}->{'size'};

		#print "$i: $peakHeight, $expectedPeakHeight\n";
		if ($peakHeight >= 5000)
		{
			#print a warning
			print "$i: peak height > 5000: ", bedToLine ($peak), "\n";
		}


		my $pvalue;

		if ($maxPH > 0 && $peakHeight > $maxPH)
		{
			#peak height too large to evaluate scan statistics. flagged by nd in pvalue
			print "$i: peak height out of range: ", bedToLine ($peak), "\n" if $verbose;
			$pvalue = "nd";
			next if $skipOutofRangePeaks;
		}
		else
		{
    		$pvalue = exists $resultHash{$geneId}{$peakHeight} ? 
    			$resultHash{$geneId}{$peakHeight} : calcScanStatistic ($peakHeight, $expectedPeakHeight, $geneSize / $tagSize);

    		$resultHash{$geneId}{$peakHeight} = $pvalue unless exists $resultHash{$geneId}{$peakHeight};

    		$pvalue *= $effectiveGeneNum if $multiTestCorrection;
    		$pvalue = 1e-100 if $pvalue == 0;
			$pvalue = sprintf ("%.2e", $pvalue);
		}
		
    	$peak->{'name'} = $peakId . "[gene=$geneId][PH=$peakHeight][PH0=" . 
    		sprintf ("%.2f", $expectedPeakHeight) . "][P=$pvalue]";
	
		$peak->{'name'} .= "#" . join("#", $leftBoundary, $rightBoundary, $leftHalfPH, $rightHalfPH) if $valleySeeking;
    	$peak->{'score'} = $peakHeight; #-log ($pvalue) / log(10);
    
    	print $fout bedToLine ($peak), "\n" if $pvalue <= $pvalueThreshold;
		$npeak++;
	}

	close ($fin);
	close ($fout);
	Carp::croak "no significant peaks found\n" if $npeak == 0;
}


if ($maxGap >=0)
{
	print "merge peaks ...\n" if $verbose;
	my $tmpPeakMergedBedFile = "$cache/tmp.peak.sig.merge.bed";
	$cmd = "perl $cmdDir/bedUniq.pl $ssFlag -c maxScore -maxgap $maxGap $verboseFlag $tmpPeakBedFile $tmpPeakMergedBedFile";
	system ($cmd);
	$tmpPeakBedFile = $tmpPeakMergedBedFile;
}

print "generating output...\n" if $verbose;
#output, some formatting issues
my $fin;
my $fout;
my $foutPeak;
my $foutBoundary;
my $foutHalfPH;

open ($fin, "<$tmpPeakBedFile") || Carp::croak "cannot open file $tmpPeakBedFile to read\n";
open ($fout, ">$outBedFile") || Carp::croak "cannot open file $outBedFile to write\n";

if ($outBoundaryBedFile ne '')
{
	open ($foutBoundary, ">$outBoundaryBedFile") || Carp::croak "cannot open file $outBoundaryBedFile to write\n";
}

if ($outHalfPHBedFile ne '')
{
	open ($foutHalfPH, ">$outHalfPHBedFile") || Carp::croak "cannot open file $outHalfPHBedFile to write\n";
}

my $iter = 0;
while (my $line = <$fin>)
{
	chomp $line;
	next if $line=~/^\s*$/;

	$iter++;
	my $p = lineToBed ($line);
	my $peakId = $p->{'name'};
	my ($leftBoundary, $rightBoundary, $leftHalfPH, $rightHalfPH);
	($peakId, $leftBoundary, $rightBoundary, $leftHalfPH, $rightHalfPH) = split ("#", $peakId) if $valleySeeking;

	$p->{'name'} = sprintf("%s_%d", $prefix, $iter);
	if ($geneBedFile ne '')
	{
		$peakId =~/(\[\S*)$/;
		my $sig = $1;
		$p->{'name'} .= $sig;
	}
	print $fout bedToLine ($p), "\n";

	my %pCopy = %$p;
	if ($outBoundaryBedFile ne '')
	{
		$pCopy{'chromStart'} = $leftBoundary;
		$pCopy{'chromEnd'} = $rightBoundary - 1;
		print $foutBoundary bedToLine (\%pCopy), "\n";
	}

	if ($outHalfPHBedFile ne '')
	{
		$pCopy{'chromStart'} = $leftHalfPH;
		$pCopy{'chromEnd'} = $rightHalfPH - 1;
		print $foutHalfPH bedToLine (\%pCopy), "\n";
	}
}

close ($fin);
close ($fout);
close ($foutBoundary) if $outBoundaryBedFile ne '';
close ($foutHalfPH) if $outHalfPHBedFile ne '';

system ("rm -rf $cache") unless $keepCache;



sub extractPeaks
{
	my ($tags, $strand, $valleyDepth) = @_;
	
	my @tags;
	#extract the tags on the specified strand
	foreach my $t (@$tags)
    {
        $t->{"strand"} = '+' unless exists $t->{"strand"};
        next if $strand ne 'b' && $strand ne $t->{"strand"};
        push @tags, $t;
    }
	
	#sort the tags
	@tags = sort {$a->{'chromStart'} <=> $b->{'chromStart'}} @tags;	

	my @peaks;

	my @currBlock;
	my $currEnd = -1;
	foreach my $t (@tags)
	{
		if ($t->{'chromStart'} > $currEnd + 1)
		{
			if (@currBlock > 0)
			{
				my $ret = extractPeaksBlock (\@currBlock, $valleyDepth);
				push @peaks, @$ret;
			
				#start a new block
				@currBlock = ();
			}
		}
		push @currBlock, $t;
		$currEnd = $t->{'chromEnd'};
	}

	#the last block
	my $ret = extractPeaksBlock (\@currBlock, $valleyDepth);
	push @peaks, @$ret;

	return \@peaks;
}


#an upstream bounding local maixma is an upstream local maxima whose PH is greater than the current local maxima
#simiarly, a downstream bounding local maxima is a downstream local maxima whose PH is greater than the current local maxima

#a peak is a local maxima satisfying
#a local minima with PH< valley height can be found between the upstream bounding and the current local maxima
#a local minima with PH< valley height can be found between the downstream bounding and the current local maxima


sub extractPeaksBlock
{
	my ($tags, $valleyDepth) = @_;

	if (@$tags == 1)
	{
		my $t = $tags->[0];
		$t->{'leftHalfPH'} = $t->{'chromStart'};
		$t->{'rightHalfPH'} = $t->{'chromEnd'};
		$t->{'leftBoundary'} = $t->{'chromStart'};
		$t->{'rightBoundary'} = $t->{'chromEnd'};
		
		return $tags;
	}
	my $valleyHeight = 1 - $valleyDepth;


	#Carp::croak Dumper ($tags), "\n";

	#label local maxima and minima
	#assuming the tags are already sorted here
	my @maxima;
	my @minima;
	for (my $i = 0; $i < @$tags; $i++)
	{
		$tags->[$i]->{'idx'} = $i;
		if ($i == 0)
		{
			if ($tags->[$i]->{'score'} > $tags->[$i+1]->{'score'})
			{
				push @maxima, $i;
				$tags->[$i]->{'maxima'} = $#maxima;
			}
			elsif ($tags->[$i]->{'score'} < $tags->[$i+1]->{'score'})
			{
				push @minima, $i;
				$tags->[$i]->{'minima'} = $#minima;
			}
		}
		elsif ($i > 0 && $i < @$tags - 1)
		{
			if ($tags->[$i]->{'score'} > $tags->[$i+1]->{'score'} && $tags->[$i]->{'score'} >= $tags->[$i-1]->{'score'})
			{
				push @maxima, $i;
				$tags->[$i]->{'maxima'} = $#maxima;
			}
			elsif ($tags->[$i]->{'score'} < $tags->[$i+1]->{'score'} && $tags->[$i]->{'score'} <= $tags->[$i-1]->{'score'})
			{
				push @minima, $i;
				$tags->[$i]->{'minima'} = $#minima;
			}
		}
		else
		{
			if ($tags->[$i]->{'score'} >= $tags->[$i-1]->{'score'})
			{
				push @maxima, $i;
				$tags->[$i]->{'maxima'} = $#maxima;
			}
			elsif ($tags->[$i]->{'score'} <= $tags->[$i-1]->{'score'})
			{
				push @minima, $i;
				$tags->[$i]->{'minima'} = $#minima;
			}
		}
	}
	#Carp::croak Dumper ($tags), "\n";
	
	my @peaks;
	#find the closest neighbor maxima which has bigger peak height
	for (my $i = 0; $i < @maxima; $i++)
	{
		#this is naive implementation, could improve speed further
		my $t1 = $tags->[$maxima[$i]];
		for (my $j = $i - 1; $j>= 0; $j--)
		{
			my $t2 = $tags->[$maxima[$j]];

			#to break ties
			#if both PH and size are equal, we go further on the right, but not on the left
			if ($t1->{'score'} < $t2->{'score'} || ($t1->{'score'} == $t2->{'score'} && $t1->{'chromEnd'} - $t1->{'chromStart'} < $t2->{'chromEnd'} - $t2->{'chromStart'}))
			{
				$t1->{'prev'} = $maxima[$j];
				last;
			}
		}

		for (my $j = $i + 1; $j < @maxima; $j++)
		{
			my $t2 = $tags->[$maxima[$j]];
			#if both PH and size are equal, we go further on the right, but not on the left
			if ($t1->{'score'} < $t2->{'score'} || ($t1->{'score'} == $t2->{'score'} && $t1->{'chromEnd'} - $t1->{'chromStart'} <= $t2->{'chromEnd'} - $t2->{'chromStart'}))
            {
                $t1->{'next'} = $maxima[$j];
                last;
            }
		}
	}
	#Carp::croak Dumper ($tags), "\n";

	#find if a valley exists surrounding each local maxima
	for (my $i = 0; $i < @maxima; $i++)
    {
		my $p1 = $tags->[$maxima[$i]];
		
		my $leftValleyFound = 0;
		my $rightValleyFound = 0;

		if (exists $p1->{'prev'})
		{
			my $prev = $p1->{'prev'};
			for (my $j = $maxima[$i] - 1; $j >= $prev+1; $j--)
			{
				my $v = $tags->[$j];
				next unless exists $v->{'minima'};
				if ($v->{'score'} / $p1->{'score'} <= $valleyHeight)
				{
					$leftValleyFound = 1;
					last;
				}
			}
		}
		else
		{
			$leftValleyFound = 1;
		}

		if (exists $p1->{'next'})
		{
			my $next = $p1->{'next'};
			for (my $j = $maxima[$i] + 1; $j < $next; $j++)
			{
				my $v = $tags->[$j];
				next unless exists $v->{'minima'};
				if ($v->{'score'} / $p1->{'score'} <= $valleyHeight)
                {
                    $rightValleyFound = 1;
                    last;
                }
			}
		}
		else
		{
			$rightValleyFound = 1;
		}

		push @peaks, $p1 if $leftValleyFound && $rightValleyFound;
	}
	
	for (my $i = 0; $i < @peaks; $i++)
	{
		my $p1 = $peaks[$i];
		#search peak boundary and half PH boundary
		my $leftBoundaryTag = $p1;
		my $leftHalfPHTag = 0;
			
		my $left = exists $p1->{'prev'} ? $p1->{'prev'} + 1 : 0;
		if ($i > 0)
		{
			$left = $peaks[$i-1]->{'idx'} + 1 if $left < $peaks[$i-1]->{'idx'} + 1;
		}
		for (my $j = $p1->{'idx'} - 1; $j >= $left; $j--)
		{
			my $v = $tags->[$j];
			if ($v->{'score'} / $p1->{'score'} <= 0.5)
			{
				#the first time the coverage reduced to 1/2PH
				$leftHalfPHTag = $v unless $leftHalfPHTag;
			}
				
			if ($leftBoundaryTag->{'score'} > $v->{'score'})
			{
				$leftBoundaryTag = $v;
			}
		}
		$leftHalfPHTag = $leftBoundaryTag unless $leftHalfPHTag;

		my $rightBoundaryTag = $p1;
		my $rightHalfPHTag = 0;
		my $right = exists $p1->{'next'} ? $p1->{'next'} - 1 : $#$tags;
		if ($i < @peaks - 1)
		{
			$right = $peaks[$i+1]->{'idx'} - 1 if $right > $peaks[$i+1]->{'idx'} - 1;
		}

		for (my $j = $p1->{'idx'} + 1; $j <= $right; $j++)
		{
			my $v = $tags->[$j];
			if ($v->{'score'} / $p1->{'score'} <= 0.5)
            {
				$rightHalfPHTag = $v unless $rightHalfPHTag;
			}
			
			if ($rightBoundaryTag->{'score'} > $v->{'score'})
			{
				$rightBoundaryTag = $v;
			}
		}
		$rightHalfPHTag = $rightBoundaryTag unless $rightHalfPHTag;
		$p1->{'leftHalfPH'} = $leftHalfPHTag->{'idx'} < $p1->{'idx'} ? ($leftHalfPHTag->{'chromEnd'} + 1) : $leftHalfPHTag->{'chromStart'};
		$p1->{'rightHalfPH'} = $rightHalfPHTag->{'idx'} > $p1->{'idx'} ? ($rightHalfPHTag->{'chromStart'} - 1) : $rightHalfPHTag->{'chromEnd'};
		$p1->{'leftBoundary'} = $leftBoundaryTag->{'idx'} < $p1->{'idx'} ? $leftBoundaryTag->{'chromEnd'} + 1 : $leftBoundaryTag->{'chromStart'};
		$p1->{'rightBoundary'} = $rightBoundaryTag->{'idx'} > $p1->{'idx'} ? $rightBoundaryTag->{'chromStart'} - 1 : $rightBoundaryTag->{'chromEnd'};
		
	}

=debug
	if ($tags->[0]->{'chrom'} eq 'chr1' && $tags->[0]->{'strand'} eq '+' && $tags->[0]->{'chromStart'} > 66439247 && $tags->[$#$tags]->{'chromEnd'} < 66439590)
	{
		print Dumper ($tags), "\n";
		print "maxima=", join ("\t", @maxima), "\n";
		print "minima=", join ("\t", @minima), "\n";
		Carp::croak Dumper (\@peaks), "\n";
	}
=cut
	return \@peaks;
}

sub getLocationInfo
{
    my ($conf, $dbkey, $analysis) = @_;

    my $fin;

    open ($fin, "<$conf") || Carp::croak "cannot open file $conf\n";

    my %ret;

    while (my $line = <$fin>)
    {
        chomp $line;
        next if $line =~/^\s*$/;
        next if $line =~/^\#/;

        my ($db, $ana, $path, $type) = split (/\s+/, $line);

        $path = "$cmdDir/$path" unless $path=~/^\//;
        #if a relative path is provided, we assume the annotation file is located in the same folder as the script
        #fixed by CZ, 07/31/2016

        $type = $ana unless $type;

        if ($db eq $dbkey && $ana eq $analysis)
        {
            Carp::croak "$path does not exist\n" unless -f $path;
            $ret{$type} = $path;
        }
    }
    close ($fin);
    return \%ret;
}

---------------------------------------###normalization with SMInput###---------------------------------------------------------------------
use warnings;
use strict;
use Statistics::Basic qw(:all);


my %rbp_list;
my @peak_filelist;
my %clipshort_to_peakshort;
my @clip_bam_fi_shorts;
my @peak_filelist_shorts;

my $filist_fi = $ARGV[0];
my $output_folder = $ARGV[1];

unless ($filist_fi && $output_folder) {
    print STDERR "Usage Error\n";
    print STDERR "Usage: perl Peak_input_normalization_wrapper.pl filist_fi output_folder\n";
    exit;
}

## Reads in mapped_read_num file if it already exists - useful for re-running analysis more quickly on the same manifest file
my %mapped_num;
my $filist_fi_mappedreadnums = $filist_fi.".mapped_read_num";
if (-e $filist_fi_mappedreadnums) {
    open(READNUM,"$filist_fi_mappedreadnums");
    for my $line (<READNUM>) {
	chomp($line);
	my ($fi,$num) = split(/\t/,$line);
	$mapped_num{$fi} = $num;
    }
    close(READNUM);
}

unless ($output_folder =~ /\/$/) {
    $output_folder = $output_folder."/";
}

my @rep_listing;
my $type_flag;

my %peakfi2uid;

## First, read in manifest file & do pre-processing to pair datasets with paired inputs, get usable read #s if not done yet, and define replicate structure
open(F,$filist_fi);
for my $line (<F>) {
    chomp($line);
    $line =~ s/\r//g;
    my @tmp = split(/\s+/,$line);
    next unless ($tmp[0]);
    next if ($tmp[0] eq "uID");

## IMPORTANT: this script is written for two manifest file structures: 
## 1) a 5 column structure where column 4 is CLIP and column 5 is SMInput
## 2) a 6 column structure where column 4 is CLIP rep1, column 5 is CLIP rep2, and column 6 is a single SMInput used for both
## This will not run properly if the manifest is structured differently

    if (scalar(@tmp) == 6) {
	$type_flag = "two_replicate_ENCODEstyle";
    } elsif (scalar(@tmp) == 5) {
	$type_flag = "one_replicate";
    }

    my $uid = shift(@tmp);
    my $rbp = shift(@tmp);
    my $cellline = shift(@tmp);
    my %CLIP;
    $CLIP{"_01"} = shift(@tmp);
    $CLIP{"_02"} = shift(@tmp) if ($type_flag eq "two_replicate_ENCODEstyle");
    my $input = shift(@tmp);

    $CLIP{"_01"} =~ s/\.bam$//;
    $CLIP{"_02"} =~ s/\.bam$// if ($type_flag eq "two_replicate_ENCODEstyle");
    $input =~ s/\.bam$//;

    if ($type_flag eq "two_replicate_ENCODEstyle") {
	@rep_listing = ("_01","_02");
    } elsif ($type_flag eq "one_replicate") {
	@rep_listing = ("_01");
    } else {
	print STDERR "TYPE flag is not set properly!!!!\n";
    }

    next if ($CLIP{"_01"} eq "NA" || $input eq "NA");
    if ($type_flag eq "two_replicate_ENCODEstyle") {
	next if ($CLIP{"_02"} eq "NA");
    }
    for my $rep (@rep_listing) {

	my @clip_fi_split = split(/\//,$CLIP{$rep});
	my $clip_fi_short = $clip_fi_split[$#clip_fi_split];

	my $clip_bam_fi_short = $clip_fi_short.".bam";
	my $clip_bam_fi_softlink = $output_folder.$clip_bam_fi_short;
	my $clip_bam_fi = $CLIP{$rep}.".bam";
	push @clip_bam_fi_shorts,$clip_bam_fi_short;
	
	my @input_fi_split = split(/\//,$input);
	my $input_fi_short = $input_fi_split[$#input_fi_split];

	my $input_bam_fi_short = $input_fi_short.".bam";
	my $input_bam_fi_softlink = $output_folder.$input_bam_fi_short;
	my $input_bam_fi = $input.".bam";
	
	my $peak_fi_short = $clip_fi_short.".peaks.bed";
	my $peak_fi_softlink = $output_folder.$peak_fi_short;
	my $peak_fi = $CLIP{$rep}.".peaks.bed";

	$peakfi2uid{$peak_fi} = $uid.$rep;
	push @peak_filelist,$peak_fi;
	push @peak_filelist_shorts,$peak_fi_short;
	$clipshort_to_peakshort{$clip_bam_fi_short} = $peak_fi_short;
	
	my $output = $output_folder.$uid.$rep.".basedon_".$uid.$rep.".peaks.l2inputnormnew.bed";
	unless (-e $clip_bam_fi && -e $input_bam_fi) {
	    print STDERR "ERROR ERROR one of these files doesn't exist $clip_bam_fi $input_bam_fi\n";
	    next;
	}
	system("ln -s $clip_bam_fi $clip_bam_fi_softlink") unless (-e $clip_bam_fi_softlink);
	system("ln -s $input_bam_fi $input_bam_fi_softlink") unless (-e $input_bam_fi_softlink);
	system("ln -s $peak_fi $peak_fi_softlink") unless (-e $peak_fi_softlink);

	unless (exists $mapped_num{$clip_bam_fi_short}) {
	    my $mapped_read_num = `samtools view -c -F 4 $clip_bam_fi_softlink`;
	    $mapped_num{$clip_bam_fi_short} = $mapped_read_num;
	}
	unless (exists $mapped_num{$input_bam_fi_short}) {
	    my $input_read_num = `samtools view -c -F 4 $input_bam_fi_softlink`;
	    $mapped_num{$input_bam_fi_short} = $input_read_num;
	}

	if (-e $output) {
	    print STDERR "skipping $output alreadydone\n";
	    next;
	}
    }
}
close(F);


open(READNUMOUT,">$filist_fi_mappedreadnums");
for my $fi (keys %mapped_num) {
    chomp($mapped_num{$fi});
    print READNUMOUT "$fi\t$mapped_num{$fi}\n";
}
close(READNUMOUT);

my %foldenriched;
open(F,$filist_fi);
for my $line (<F>) {
    chomp($line);
    $line =~ s/\r//g;
    my @tmp = split(/\s+/,$line);
    next if ($tmp[0] eq "uID");


    my $uid = shift(@tmp);
    my $rbp = shift(@tmp);
    my $cellline = shift(@tmp);
    my %CLIP;
    $CLIP{"_01"} = shift(@tmp);
    $CLIP{"_02"} = shift(@tmp) if ($type_flag eq "two_replicate_ENCODEstyle");
    my $input = shift(@tmp);

    $CLIP{"_01"} =~ s/\.bam$//;
    $CLIP{"_02"} =~ s/\.bam$// if ($type_flag eq "two_replicate_ENCODEstyle");
    $input =~ s/\.bam$//;

    
    my $next_flag = 0;
    for my $rep (@rep_listing) {
	$next_flag = 1 if ($CLIP{$rep} eq "NA");
    } 
    $next_flag = 1 if ($input eq "NA");
    next if ($next_flag == 1);
    
    for my $rep (@rep_listing) {

        my @clip_fi_split = split(/\//,$CLIP{$rep});
        my $clip_fi_short = $clip_fi_split[$#clip_fi_split];

        my $clip_bam_fi_short = $clip_fi_short.".bam";
        my $clip_bam_fi_softlink = $output_folder.$clip_bam_fi_short;
        my $clip_bam_fi = $CLIP{$rep}.".bam";

	my @input_fi_split = split(/\//,$input);
        my $input_fi_short = $input_fi_split[$#input_fi_split];

        my $input_bam_fi_short = $input_fi_short.".bam";
        my $input_bam_fi_softlink = $output_folder.$input_bam_fi_short;
	my $input_bam_fi = $input.".bam";

        my $peak_fi_short = $clip_fi_short.".peaks.bed";
        my $peak_fi_softlink = $output_folder.$peak_fi_short;
	my $peak_fi = $CLIP{$rep}.".peaks.bed";

	unless (-e $peak_fi && -e $input_bam_fi && -e $clip_bam_fi) {
	    print STDERR "ERROR ERROR ERROR one of these doesn't exist $peak_fi $clip_bam_fi $input_bam_fi\n";
	    next;
	}

	my @desired_peak_filelist;
	$desired_peak_filelist[0] = $peak_fi;


	for my $compare_peakfi (@desired_peak_filelist) {
	    
	    my @compare_peakfii = split(/\//,$compare_peakfi);
	    my $compare_peakfi_short = $compare_peakfii[$#compare_peakfii];
	    my $compare_peakfi_softlink = $output_folder.$compare_peakfi_short;
	    my $output = $output_folder.$uid.$rep.".basedon_".$peakfi2uid{$compare_peakfi}.".peaks.l2inputnormnew.bed";
	    my $output_compressed = $output.".compressed.bed";
	    
	    ## For faster re-running - will pick up where it left off and not overwrite files. Output to a new output_directory if full re-run is desired
	    if (-e $output) {
		print STDERR "skipping $output alreadydone\n";
		if (-e $output_compressed) {
		} else {
		    system("perl /home/gbb/NGS/tools/Yeo/gscripts-1.1/perl_scripts/compress_l2foldenrpeakfi.pl $output");
		}
	    } else {
		system("perl /home/gbb/NGS/tools/Yeo/gscripts-1.1/perl_scripts/overlap_peakfi_with_bam_PE.pl $clip_bam_fi_softlink $input_bam_fi_softlink $compare_peakfi_softlink $filist_fi_mappedreadnums $output");
		system("perl /home/gbb/NGS/tools/Yeo/gscripts-1.1/perl_scripts/compress_l2foldenrpeakfi.pl $output");
	    }

	}
    }
}
close(F);






